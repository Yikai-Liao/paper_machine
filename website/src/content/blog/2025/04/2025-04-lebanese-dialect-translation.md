---
title: "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese"
pubDatetime: 2025-04-30T18:33:53+00:00
slug: "2025-04-lebanese-dialect-translation"
type: "arxiv"
id: "2505.00114"
score: 0.694935748460737
author: "grok-3-latest"
authors: ["Silvana Yakhni", "Ali Chehab"]
tags: ["LLM", "Low-Resource Translation", "Cultural Authenticity", "Fine-Tuning", "Contrastive Learning"]
institution: ["American University of Beirut"]
description: "本文通过文化真实性数据和对比指令微调策略，显著提升了大型语言模型在黎巴嫩方言翻译中的性能，强调数据质量优于数量，并引入 LebEval 基准以真实评估方言翻译能力。"
---

> **Summary:** 本文通过文化真实性数据和对比指令微调策略，显著提升了大型语言模型在黎巴嫩方言翻译中的性能，强调数据质量优于数量，并引入 LebEval 基准以真实评估方言翻译能力。 

> **Keywords:** LLM, Low-Resource Translation, Cultural Authenticity, Fine-Tuning, Contrastive Learning

**Authors:** Silvana Yakhni, Ali Chehab

**Institution(s):** American University of Beirut


## Problem Background

黎巴嫩方言作为低资源阿拉伯语变体，具有浓厚的文化背景和独特的语言特征，但现有大型语言模型（LLMs）在处理此类方言时表现不佳，尤其是在捕捉文化细微差别和地区特有习语方面。
论文旨在解决低资源方言翻译中的数据匮乏和文化失真问题，探索如何通过微调和提示策略提升模型性能，同时挑战‘数据量越多越好’的传统观念，强调文化真实性数据的重要性。

## Method

*   **核心思想:** 通过微调大型语言模型（基于 Aya23-8B），结合文化真实性数据和多种指令策略，提升黎巴嫩方言到英语的翻译质量。
*   **具体方法:**
    *   **基本翻译指令微调（Instruct-MT）:** 使用双语句对，将黎巴嫩方言翻译为英语，采用聊天格式，确保模型具备基础翻译能力。
    *   **对比指令微调（Instruct-Cont）:** 提供优选和次优翻译示例，让模型学习区分翻译质量差异，通过暴露于错误示例增强对翻译错误的辨别能力。
    *   **语法提示指令微调（Instruct-Grammar）:** 引入语法和词汇规则提示，帮助模型在翻译前进行推理，提升对黎巴嫩方言特有语法结构的理解，例如‘rah’表示将来时的用法。
    *   **课程学习策略:** 尝试分阶段微调，如先学习对比或语法规则，再进行翻译任务，探索是否能逐步提升模型能力。
    *   **提示策略:** 包括零样本提示（简单指令）、少样本提示（加入示例）和对比提示（包含好坏翻译示例），以进一步优化翻译输出。
    *   **数据选择:** 对比文化真实性高的黎巴嫩数据集（LanguageWave, LW，约 3K 句）和较大但非本土的翻译数据集（Non-Native, NN，约 140K 句），验证数据质量对翻译效果的影响。
*   **关键点:** 方法强调文化相关性数据的价值，并通过对比学习和语法提示增强模型的推理能力，同时探索提示策略对翻译质量的辅助作用。

## Experiment

*   **有效性:** 基于文化真实性数据集（LW）微调的模型在所有提示策略下均优于基于非本土数据集（NN）的模型，尤其在 LebEval 基准上，对比指令微调（Instruct-Cont-LW）结合对比提示（C3-shot）取得了最佳性能（xCOMET 得分 74.4），比基础模型提升约 3-5 个百分点。
*   **优越性:** 对比微调显著优于基本翻译指令微调，尤其在处理文化细微差别时表现突出；文化真实性数据的作用不可替代，LW 模型普遍优于 NN 模型，验证了数据质量比数据量更重要。
*   **局限性:** 课程学习未带来显著提升，可能是由于灾难性遗忘问题；偏好对齐方法（CPO）表现不及监督微调（SFT），可能受限于偏好数据质量。
*   **实验设置合理性:** 实验设置较为全面，涵盖多种微调和提示策略，并引入 LebEval 作为文化真实性评价基准，揭示了传统基准（如 FLoRes）在评估方言翻译时的局限性；但 LW 数据集规模较小（3K 句），可能限制了模型潜力的充分发挥。
*   **开销:** 微调采用 Qlora 高效方法，基于 4 个 Nvidia L40S GPU 进行训练，计算成本可控，但少样本和对比提示增加了推理时计算开销。

## Further Thoughts

论文强调文化真实性数据的重要性，启发我思考是否可以通过社交媒体或口语记录采集更多本土内容，构建类似 LW 的数据集，覆盖更多低资源方言；对比学习在翻译任务中的成功应用，让我考虑是否可以将‘学习错误’的思路扩展到其他 NLP 任务，如文本生成或问答系统，通过引入负面示例提升模型鲁棒性；此外，LebEval 的提出揭示了评价基准的文化适配性问题，未来是否可以开发更多针对特定方言或文化背景的评价工具，以更真实地反映模型能力？