# 嵌入模型配置
[embedding]
# API 配置
api_key = "env"  # 使用环境变量 EMBEDDING_API_KEY
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
model = "text-embedding-v3"
dim = 1024

# 输入输出路径配置
input_csv = "data/arxiv_latest.csv"
output_npy = "data/arxiv_latest.npy"

# arXiv 爬虫配置
[arxiv_crawler]
# 爬取天数和类别
days = 1
category = ["cs.AI"]
# API 请求配置
max_results = 500
delay_seconds = 3.0
# 输出文件路径
output_file = "data/arxiv_latest.csv"

# 引导数据集构建配置
[bootstrap]
# 输入输出路径
bootstrap_input_csv = "data/bootstrap_raw.csv"
output_csv = "data/preference/bootstrap.csv"
output_npy = "data/preference/bootstrap.npy"
# API 请求配置
arxiv_fetch_delay = 5.0

# 模型训练配置
[model_fitting]
# 数据路径
preference_dir = "data/preference"
background_file = "data/arxiv_background.csv"
target_file = "data/arxiv_latest.csv"

# 训练参数
neg_ratio = 5.0
folds = 5
beta = 1.5
random_state = 42

# 采样参数
target_sample_rate = 0.2
high_percentile = 90
boundary_percentile = 50

# 过采样配置
oversample_method = "borderline-smote"  # 可选: "none", "borderline-smote", "adasyn"
oversample_ratio = 0.5

# 置信度加权配置
confidence_weighted = true
high_conf_threshold = 0.9
high_conf_weight = 2.0
high_conf_boost = 1.2

# 可视化配置
sample = 5  # 每个分数区间显示的样本数量
visualization_dir = "data/visualizations"  # 可视化图表保存目录

[summary]
# Replace with your actual API key if needed, or leave empty if using environment variables
api_key = "env" 
# Replace with your OpenAI-compatible API base URL
base_url = "https://api.x.ai/v1" 
# Specify the model to use
model = "grok-3-latest"
# Sampling temperature
temperature = 0 
# Top-p nucleus sampling
top_p = 0.8
# Maximum tokens to generate in the completion
max_tokens = 20000
max_concurrent_llm_calls = 10
stream=false

# 输入 CSV 文件路径
csv_path = "data/arxiv_latest.csv"
# 输出 Markdown 文件目录
output_dir = "website/src/content/blog"
# 最大并发处理数量
max_workers = 5
# 是否启用流式 LLM 响应
stream_enabled = false
# 提示词文件路径
prompt_path = "recommend_system/prompt.txt"
# 模板文件路径
template_path = "recommend_system/template.j2"